{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## **Підготовка даних**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
      "17464789/17464789 [==============================] - 1s 0us/step\n",
      "25000 train sequences\n",
      "25000 test sequences\n",
      "Pad sequences (samples x time)\n",
      "x_train shape: (25000, 500)\n",
      "x_test shape: (25000, 500)\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import imdb\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "max_features = 10000\n",
    "maxlen = 500\n",
    "\n",
    "print('Loading data...')\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "print(len(x_train), 'train sequences')\n",
    "print(len(x_test), 'test sequences')\n",
    "\n",
    "print('Pad sequences (samples x time)')\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-18T21:36:51.874333200Z",
     "start_time": "2023-10-18T21:36:43.041736300Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    " ## **Створення моделей**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### a) RNN:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "157/157 [==============================] - 16s 86ms/step - loss: 0.6342 - acc: 0.6266 - val_loss: 0.8428 - val_acc: 0.5418\n",
      "Epoch 2/10\n",
      "157/157 [==============================] - 15s 99ms/step - loss: 0.4172 - acc: 0.8217 - val_loss: 0.3875 - val_acc: 0.8360\n",
      "Epoch 3/10\n",
      "157/157 [==============================] - 15s 94ms/step - loss: 0.3202 - acc: 0.8694 - val_loss: 0.5086 - val_acc: 0.8048\n",
      "Epoch 4/10\n",
      "157/157 [==============================] - 13s 83ms/step - loss: 0.2727 - acc: 0.8923 - val_loss: 0.3769 - val_acc: 0.8504\n",
      "Epoch 5/10\n",
      "157/157 [==============================] - 15s 94ms/step - loss: 0.2163 - acc: 0.9180 - val_loss: 0.4067 - val_acc: 0.8200\n",
      "Epoch 6/10\n",
      "157/157 [==============================] - 15s 99ms/step - loss: 0.1775 - acc: 0.9344 - val_loss: 0.3882 - val_acc: 0.8414\n",
      "Epoch 7/10\n",
      "157/157 [==============================] - 15s 95ms/step - loss: 0.1300 - acc: 0.9549 - val_loss: 0.5002 - val_acc: 0.8076\n",
      "Epoch 8/10\n",
      "157/157 [==============================] - 13s 85ms/step - loss: 0.0931 - acc: 0.9694 - val_loss: 0.4880 - val_acc: 0.8480\n",
      "Epoch 9/10\n",
      "157/157 [==============================] - 13s 85ms/step - loss: 0.0657 - acc: 0.9803 - val_loss: 0.5971 - val_acc: 0.8130\n",
      "Epoch 10/10\n",
      "157/157 [==============================] - 14s 89ms/step - loss: 0.0499 - acc: 0.9869 - val_loss: 0.6088 - val_acc: 0.8200\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, SimpleRNN, Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 32))\n",
    "model.add(SimpleRNN(32))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "history_rnn = model.fit(x_train, y_train, epochs=10, batch_size=128, validation_split=0.2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-18T21:39:16.636141500Z",
     "start_time": "2023-10-18T21:36:51.874333200Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### b) LSTM:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "157/157 [==============================] - 34s 208ms/step - loss: 0.5990 - acc: 0.6823 - val_loss: 0.5088 - val_acc: 0.7478\n",
      "Epoch 2/10\n",
      "157/157 [==============================] - 32s 205ms/step - loss: 0.3607 - acc: 0.8528 - val_loss: 0.3134 - val_acc: 0.8744\n",
      "Epoch 3/10\n",
      "157/157 [==============================] - 33s 210ms/step - loss: 0.2756 - acc: 0.8930 - val_loss: 0.5315 - val_acc: 0.8242\n",
      "Epoch 4/10\n",
      "157/157 [==============================] - 33s 208ms/step - loss: 0.2349 - acc: 0.9107 - val_loss: 0.3051 - val_acc: 0.8722\n",
      "Epoch 5/10\n",
      "157/157 [==============================] - 35s 223ms/step - loss: 0.2049 - acc: 0.9244 - val_loss: 0.2874 - val_acc: 0.8926\n",
      "Epoch 6/10\n",
      "157/157 [==============================] - 33s 211ms/step - loss: 0.1843 - acc: 0.9337 - val_loss: 0.3998 - val_acc: 0.8634\n",
      "Epoch 7/10\n",
      "157/157 [==============================] - 31s 199ms/step - loss: 0.1637 - acc: 0.9416 - val_loss: 0.4007 - val_acc: 0.8528\n",
      "Epoch 8/10\n",
      "157/157 [==============================] - 30s 191ms/step - loss: 0.1499 - acc: 0.9477 - val_loss: 0.3218 - val_acc: 0.8592\n",
      "Epoch 9/10\n",
      "157/157 [==============================] - 30s 190ms/step - loss: 0.1366 - acc: 0.9521 - val_loss: 0.3603 - val_acc: 0.8844\n",
      "Epoch 10/10\n",
      "157/157 [==============================] - 30s 188ms/step - loss: 0.1278 - acc: 0.9570 - val_loss: 0.3776 - val_acc: 0.8736\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import LSTM\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 32))\n",
    "model.add(LSTM(32))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "history_lstm = model.fit(x_train, y_train, epochs=10, batch_size=128, validation_split=0.2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-18T21:44:37.807888400Z",
     "start_time": "2023-10-18T21:39:16.638140200Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### c) Двосторонній LSTM:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "157/157 [==============================] - 66s 402ms/step - loss: 0.6310 - acc: 0.6316 - val_loss: 0.4757 - val_acc: 0.7998\n",
      "Epoch 2/10\n",
      "157/157 [==============================] - 58s 372ms/step - loss: 0.3928 - acc: 0.8357 - val_loss: 0.3882 - val_acc: 0.8288\n",
      "Epoch 3/10\n",
      "157/157 [==============================] - 58s 372ms/step - loss: 0.2925 - acc: 0.8835 - val_loss: 0.3375 - val_acc: 0.8590\n",
      "Epoch 4/10\n",
      "157/157 [==============================] - 57s 365ms/step - loss: 0.2429 - acc: 0.9083 - val_loss: 0.3576 - val_acc: 0.8448\n",
      "Epoch 5/10\n",
      "157/157 [==============================] - 57s 365ms/step - loss: 0.2092 - acc: 0.9230 - val_loss: 0.3599 - val_acc: 0.8686\n",
      "Epoch 6/10\n",
      "157/157 [==============================] - 59s 373ms/step - loss: 0.1851 - acc: 0.9322 - val_loss: 0.3284 - val_acc: 0.8830\n",
      "Epoch 7/10\n",
      "157/157 [==============================] - 58s 367ms/step - loss: 0.1673 - acc: 0.9394 - val_loss: 0.7204 - val_acc: 0.8280\n",
      "Epoch 8/10\n",
      "157/157 [==============================] - 69s 437ms/step - loss: 0.1558 - acc: 0.9446 - val_loss: 0.3344 - val_acc: 0.8700\n",
      "Epoch 9/10\n",
      "157/157 [==============================] - 68s 432ms/step - loss: 0.1407 - acc: 0.9516 - val_loss: 0.3432 - val_acc: 0.8814\n",
      "Epoch 10/10\n",
      "157/157 [==============================] - 57s 363ms/step - loss: 0.1291 - acc: 0.9560 - val_loss: 0.3272 - val_acc: 0.8812\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Bidirectional\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 32))\n",
    "model.add(Bidirectional(LSTM(32)))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "history_bi_lstm = model.fit(x_train, y_train, epochs=10, batch_size=128, validation_split=0.2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-18T21:54:45.463266300Z",
     "start_time": "2023-10-18T21:44:37.807888400Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### d) Глибока LSTM:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "157/157 [==============================] - 101s 614ms/step - loss: 0.6220 - acc: 0.6180 - val_loss: 0.5756 - val_acc: 0.7152\n",
      "Epoch 2/10\n",
      "157/157 [==============================] - 95s 605ms/step - loss: 0.3726 - acc: 0.8420 - val_loss: 0.3951 - val_acc: 0.8514\n",
      "Epoch 3/10\n",
      "157/157 [==============================] - 95s 607ms/step - loss: 0.2783 - acc: 0.8925 - val_loss: 0.3077 - val_acc: 0.8768\n",
      "Epoch 4/10\n",
      "157/157 [==============================] - 123s 787ms/step - loss: 0.2283 - acc: 0.9146 - val_loss: 0.5401 - val_acc: 0.7862\n",
      "Epoch 5/10\n",
      "157/157 [==============================] - 131s 835ms/step - loss: 0.1993 - acc: 0.9279 - val_loss: 0.3535 - val_acc: 0.8706\n",
      "Epoch 6/10\n",
      "157/157 [==============================] - 138s 876ms/step - loss: 0.1723 - acc: 0.9395 - val_loss: 0.3168 - val_acc: 0.8724\n",
      "Epoch 7/10\n",
      "157/157 [==============================] - 124s 789ms/step - loss: 0.1461 - acc: 0.9489 - val_loss: 0.3570 - val_acc: 0.8824\n",
      "Epoch 8/10\n",
      "157/157 [==============================] - 111s 706ms/step - loss: 0.1324 - acc: 0.9552 - val_loss: 0.3325 - val_acc: 0.8646\n",
      "Epoch 9/10\n",
      "157/157 [==============================] - 114s 726ms/step - loss: 0.1121 - acc: 0.9628 - val_loss: 0.4224 - val_acc: 0.8536\n",
      "Epoch 10/10\n",
      "157/157 [==============================] - 114s 727ms/step - loss: 0.0953 - acc: 0.9683 - val_loss: 0.4465 - val_acc: 0.8742\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 32))\n",
    "model.add(LSTM(32, return_sequences=True))\n",
    "model.add(LSTM(32, return_sequences=True))\n",
    "model.add(LSTM(32))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "history_deep_lstm = model.fit(x_train, y_train, epochs=10, batch_size=128, validation_split=0.2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-18T22:13:52.730601100Z",
     "start_time": "2023-10-18T21:54:45.463266300Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### За результатами навчання різних моделей нейронних мереж на датасеті IMDb можна зробити наступні висновки:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1. Звичайна RNN:\n",
    "\n",
    "#### * Найбільш проста модель з наведених.\n",
    "#### * Швидше за все навчається, але якість класифікації (val_acc) на валідаційних даних залишає бажати кращого в порівнянні з іншими моделями.\n",
    "#### * Схильна до перенавчання (overfitting), що видно з розриву між acc та val_acc.\n",
    "\n",
    "#### 2. LSTM:\n",
    "\n",
    "#### * Показала кращі результати на валідаційних даних в порівнянні зі звичайною RNN.\n",
    "#### * За часом навчання середньої складності.\n",
    "#### * Схильність до перенавчання менша, але все ж присутня.\n",
    "\n",
    "#### 3. Двосторонній LSTM (Bidirectional LSTM):\n",
    "\n",
    "#### * Ця модель використовує інформацію з минулого і майбутнього для кращого розуміння контексту.\n",
    "#### * Показала дуже добрі результати на валідаційних даних.\n",
    "#### * Навчання відбувається повільніше, ніж у попередніх моделей.\n",
    "\n",
    "#### 4. Глибока LSTM:\n",
    "\n",
    "#### * Найскладніша модель з наведених.\n",
    "#### * Показала добрі результати на валідаційних даних.\n",
    "#### * Найбільш часозатратна модель з усіх.\n",
    "#### * Схильність до перенавчання є, але вона не так сильно виражена, як у звичайної RNN.\n",
    "\n",
    "#### Загальний висновок: з усіх розглянутих моделей, двосторонній LSTM показав найкращі результати на валідаційних даних, але при цьому вимагає більше часу на навчання. Якщо враховувати баланс між якістю і швидкістю навчання, то LSTM може бути хорошим варіантом для вирішення подібних задач класифікації текстових даних."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
